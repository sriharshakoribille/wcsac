{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8afe246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile Regression Critic\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcda9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(layers):\n",
    "    for layer in layers:\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee83753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QR_SafetyCritic(nn.Module):\n",
    "    \"\"\"Quantile Regression Safety Critic\n",
    "        Args:\n",
    "            obs_dim: state dimension\n",
    "            action_dim: action dimensions (countinous action space)\n",
    "            hidden_dim: -\n",
    "            num_qunatiles: number of quantiles to approximate quantile distribution (32 in paper)\n",
    "            risk_level: if risk_level is given, cvar is directly appoximated by a single quantile\n",
    "                        sampled from U(1-risk_level,1)\n",
    "    \"\"\"\n",
    "    def __init__(self, obs_dim, action_dim, hidden_dim, num_quantiles, risk_level=None):\n",
    "        super(QR_SafetyCritic, self).__init__()\n",
    "\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.num_q = num_quantiles\n",
    "\n",
    "        if risk_level:\n",
    "            # approximate cvar quantile\n",
    "            self.risk_level = 1-risk_level  # ValueAtRisk\n",
    "            self.num_q = 1\n",
    "\n",
    "        self.head = nn.Linear(self.obs_dim + self.action_dim, hidden_dim)\n",
    "        self.lin1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, self.num_q)\n",
    "        weight_init([self.head, self.lin1])\n",
    "    \n",
    "    def forward(self, s, a):\n",
    "        \"\"\"Forward fct of QR-safety critic\n",
    "        Args:\n",
    "            input: (state, action)\n",
    "        Returns:\n",
    "            Quantile distribution of cost / approximated cvar\n",
    "        \"\"\"\n",
    "        obs_action = torch.cat([s, a], dim=-1)\n",
    "        x = torch.relu(self.head(obs_action))\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        out = self.lin2(x)\n",
    "        return out.view(obs_action.shape[0], self.num_q, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6eccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "critic = QR_SafetyCritic(obs_dim=10, action_dim=10, hidden_dim=64, num_quantiles=32)\n",
    "s = torch.randn(1, 10)\n",
    "a = torch.randn(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee63540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic(s,a).shape  # do we want to keep this shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a77a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUANTILE REGRESSION LOSS + HUBER LOSS\n",
    "def calculate_huber_loss_and_quantile_loss(td_errors, k=1.0, n=32):\n",
    "    \"\"\"\n",
    "    Calculate huber loss element-wisely depending on kappa k.\n",
    "    \"\"\"\n",
    "    huber_l = torch.where(td_errors.abs() <= k, 0.5 * td_errors.pow(2), k * (td_errors.abs() - 0.5 * k))\n",
    "    #print(huber_l.shape)\n",
    "    assert huber_l.shape == (td_errors.shape[0], n, n), \"huber loss has wrong shape\"\n",
    "    \n",
    "    quantile_tau = torch.FloatTensor([i/n for i in range(1,n+1)])\n",
    "    #print(quantile_tau)\n",
    "    quantil_l = abs(quantile_tau -(td_errors.detach() < 0).float()) * huber_l / 1.0\n",
    "    #print(quantil_l.shape)\n",
    "    return quantil_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "087728bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size, ...\n",
    "batch_size = 12\n",
    "obs_dim = 10\n",
    "action_dim = 10\n",
    "num_quantiles = 32\n",
    "\n",
    "# initialize qr-networks\n",
    "critic = QR_SafetyCritic(obs_dim=10, action_dim=10, hidden_dim=64, num_quantiles=num_quantiles)\n",
    "critic_target = QR_SafetyCritic(obs_dim=10, action_dim=10, hidden_dim=64, num_quantiles=num_quantiles)\n",
    "\n",
    "# assume some batch_sample\n",
    "states = torch.randn(batch_size, obs_dim)\n",
    "actions = torch.randn(batch_size, action_dim)\n",
    "next_states = torch.randn(batch_size, obs_dim)\n",
    "rewards = torch.randn(batch_size, 1)\n",
    "dones = torch.zeros(batch_size, 1)\n",
    "# simulate policy\n",
    "next_action_new = torch.randn(batch_size, action_dim)\n",
    "\n",
    "# calculate q-targets\n",
    "# td-target: r + (gamma)*(1-d)*Q(next_state,a_new')\n",
    "q_target_next = critic_target(next_states, next_action_new).transpose(1,2)  # (bs,N,1) -> (bs,1,N)\n",
    "assert q_target_next.shape == (batch_size,1, num_quantiles)\n",
    "q_target = rewards.unsqueeze(-1) + 0.99 * (1-dones.unsqueeze(-1)) * q_target_next\n",
    "q = critic(states, actions)\n",
    "td = q_target - q\n",
    "assert td.shape == (batch_size, num_quantiles, num_quantiles)\n",
    "#print(q_target.shape)\n",
    "#print(q.shape)\n",
    "#print(td_error.shape)\n",
    "loss = calculate_huber_loss_and_quantile_loss(td)\n",
    "loss = loss.sum(dim=1).mean(dim=1)  # formula 8.5 // not entirely sure if we should sum first and then take mean\n",
    "loss = loss.mean()  # take mean over batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50f52ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6506, -0.3148,  1.2832,  1.9226, -0.0061],\n",
      "        [-2.9070,  1.6208, -2.3225,  1.3767, -0.1619]])\n",
      "tensor([[ 1.9226, -0.0061],\n",
      "        [ 1.3767, -0.1619]])\n",
      "tensor([[0.9582],\n",
      "        [0.6074]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,5,1)\n",
    "print(x.squeeze(-1))\n",
    "print(x.squeeze(-1)[:, -2:])\n",
    "print(x.squeeze(-1)[:, -2:].mean(-1, keepdim=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
